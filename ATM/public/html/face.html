<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition Login</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
            margin: 0;
        }
        #video-container {
            position: relative;
            width: 640px;
            height: 480px;
        }
        #video {
            width: 100%;
            height: auto;
            border-radius: 8px;
        }
    </style>
</head>
<body>
    <div id="video-container">
        <video id="video" autoplay muted></video>
    </div>
    
    <!-- Load face-api.js from CDN -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script>
        async function setupCamera() {
            const video = document.getElementById('video');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = stream;
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        resolve(video);
                    };
                });
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
        }

        async function loadModels() {
            // Load face detection and recognition models
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
            console.log("Models loaded");
        }

        async function detectFaces(video) {
            const options = new faceapi.TinyFaceDetectorOptions();

            video.addEventListener('play', async () => {
                const canvas = faceapi.createCanvasFromMedia(video);
                document.getElementById('video-container').append(canvas);

                const displaySize = { width: video.width, height: video.height };
                faceapi.matchDimensions(canvas, displaySize);

                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video, options).withFaceLandmarks().withFaceDescriptors();
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);

                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

                    if (detections.length > 0) {
                        console.log("Face detected", detections);
                        // Perform additional checks or trigger login success
                    }
                }, 100);
            });
        }

        // Initialize the face recognition setup
        async function init() {
            await loadModels();
            const video = await setupCamera();
            detectFaces(video);
        }

        init();
    </script>
</body>
</html>
